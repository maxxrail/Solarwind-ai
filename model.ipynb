{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Necessary Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ONCE DETECTRON2 IS INSTALLED, PLEASE COPY THE CONTENTS FROM THE SUBFOLDER DETECTRON2 FOLDER TO THE MAIN DETECTRON2 FOLDER!!!\n",
    "\n",
    "# Upgrade pip\n",
    "%pip install --upgrade pip\n",
    "\n",
    "# Install OpenCV for image processing\n",
    "%pip install opencv-python\n",
    "\n",
    "# Install numpy at the desired version\n",
    "%pip install numpy==1.26.1\n",
    "\n",
    "# Install PyTorch and related packages (adjust versions/URLs as needed for your platform)\n",
    "%pip install torch==2.0.0+cu117 torchvision==0.15.1+cu117 torchaudio==2.0.0+cu117 --index-url https://download.pytorch.org/whl/cu117\n",
    "\n",
    "# Install gitpython and cython if not already installed\n",
    "%pip install gitpython cython\n",
    "\n",
    "# Install dependencies, but pin fvcore and pycocotools to compatible versions:\n",
    "%pip install cython\n",
    "\n",
    "# Install fvcore.\n",
    "%pip install fvcore==0.1.5.post20221221\n",
    "\n",
    "# Install pycocotools\n",
    "%pip install pycocotools==2.0.8\n",
    "\n",
    "# ---- Additional installations ----\n",
    "%pip install docutils==0.19\n",
    "%pip install sphinx==7\n",
    "%pip install recommonmark==0.6.0\n",
    "%pip install sphinx_rtd_theme\n",
    "%pip install termcolor\n",
    "%pip install yacs\n",
    "%pip install tabulate\n",
    "%pip install cloudpickle\n",
    "%pip install future\n",
    "# (The following two lines with CPU wheels are for Linux CP37; comment them out if not needed)\n",
    "# %pip install https://download.pytorch.org/whl/cpu/torch-1.8.1%2Bcpu-cp37-cp37m-linux_x86_64.whl\n",
    "# %pip install https://download.pytorch.org/whl/cpu/torchvision-0.9.1%2Bcpu-cp37-cp37m-linux_x86_64.whl\n",
    "%pip install \"omegaconf>=2.1.0.dev24\"\n",
    "%pip install \"hydra-core>=1.1.0.dev5\"\n",
    "%pip install scipy\n",
    "%pip install timm\n",
    "# ---------------------------------\n",
    "\n",
    "# Clone the Detectron2 repository and install it in editable mode\n",
    "import os\n",
    "if not os.path.exists('detectron2'):\n",
    "    !git clone https://github.com/facebookresearch/detectron2.git\n",
    "\n",
    "%cd detectron2\n",
    "%pip install -e .\n",
    "%cd ..\n",
    "\n",
    "# Install TensorFlow and Keras for deep learning models\n",
    "%pip install tensorflow\n",
    "\n",
    "# Install pickleshare to fix the IPython warning\n",
    "%pip install pickleshare\n",
    "\n",
    "# Install additional required libraries\n",
    "%pip install numpy matplotlib pandas scikit-learn tqdm Pillow\n",
    "\n",
    "# Install geospatial libraries\n",
    "%pip install geopandas rasterio shapely\n",
    "\n",
    "# Install any other utility libraries if needed\n",
    "%pip install jsonschema pyyaml\n",
    "\n",
    "# Install IPython kernel to ensure compatibility\n",
    "%pip install ipykernel\n",
    "\n",
    "# After installations, you may need to restart the kernel\n",
    "print(\"All libraries installed. Please restart the kernel to ensure all packages are loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement get_roof_dicts() ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roof_dicts(img_dir):\n",
    "    dataset_dicts = []\n",
    "    img_files = sorted(glob.glob(os.path.join(img_dir, \"images\", \"*.tif\")))\n",
    "    \n",
    "    for idx, img_path in enumerate(img_files):\n",
    "        mask_path = img_path.replace(\"images\", \"gt\")  # or some other logic if needed\n",
    "        \n",
    "        height, width = cv2.imread(img_path).shape[:2]\n",
    "        \n",
    "        record = {\n",
    "            \"file_name\": img_path,\n",
    "            \"image_id\": idx,\n",
    "            \"height\": height,\n",
    "            \"width\": width,\n",
    "        }\n",
    "        \n",
    "        # Read mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        objs = []\n",
    "        for contour in contours:\n",
    "            # Flatten the contour\n",
    "            coords = contour.flatten().tolist()\n",
    "            \n",
    "            # Skip degenerate polygons\n",
    "            if len(coords) < 6:  # fewer than 3 points\n",
    "                continue\n",
    "            \n",
    "            xs = coords[0::2]\n",
    "            ys = coords[1::2]\n",
    "            x_min, x_max = min(xs), max(xs)\n",
    "            y_min, y_max = min(ys), max(ys)\n",
    "            \n",
    "            bbox = [x_min, y_min, x_max - x_min, y_max - y_min]\n",
    "            \n",
    "            # **Important**: double brackets around coords\n",
    "            obj = {\n",
    "                \"bbox\": bbox,\n",
    "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                \"segmentation\": [coords],  # nested list\n",
    "                \"category_id\": 0\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        \n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    \n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the dataset for Detectron2 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = r\"C:\\Users\\maxxr\\Desktop\\AerialImageDataset\" # Change this to your dataset path\n",
    "\n",
    "for d in [\"train\", \"val\"]:\n",
    "    dataset_dir = os.path.join(dataset_root, d)\n",
    "    DatasetCatalog.register(\n",
    "        f\"roof_{d}\",\n",
    "        lambda d=d: get_roof_dicts(os.path.join(dataset_root, d))\n",
    "    )\n",
    "    MetadataCatalog.get(f\"roof_{d}\").set(thing_classes=[\"roof\"])\n",
    "\n",
    "roof_metadata = MetadataCatalog.get(\"roof_train\")\n",
    "dataset_dicts = get_roof_dicts(os.path.join(dataset_root, \"train\"))\n",
    "print(\"Number of records in dataset:\", len(dataset_dicts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize sample data to ensure it's loaded correctly ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Randomly pick a few images\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    \n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=roof_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and train the Mask R-CNN model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        \"\"\"\n",
    "        Create evaluator for a given dataset.\n",
    "        The COCOEvaluator will compute mAP and other metrics on a COCO-formatted dataset.\n",
    "        \"\"\"\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "# Build the configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\n",
    "    model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    ")\n",
    "\n",
    "# Specify our registered datasets:\n",
    "cfg.DATASETS.TRAIN = (\"roof_train\",)\n",
    "cfg.DATASETS.TEST = (\"roof_val\",)\n",
    "\n",
    "# Standard parameters\n",
    "cfg.DATALOADER.NUM_WORKERS = 8       # adjust to number of CPU cores\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2         # images per batch\n",
    "cfg.SOLVER.BASE_LR = 0.00025         # learning rate\n",
    "cfg.SOLVER.MAX_ITER = 5000           # number of iterations (consider increasing this if needed)\n",
    "\n",
    "# Only one class: 'roof'\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "\n",
    "# Download weights from model zoo\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "    \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    ")\n",
    "\n",
    "# Force CPU usage, comment out if you have an NVIDIA GPU\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize the trainer using our subclass that includes an evaluator\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly select test image ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to you path for test images\n",
    "test_images_dir = r\"C:\\Users\\maxxr\\Desktop\\AerialImageDataset\\test\\images\"  \n",
    "\n",
    "# Valid image extensions\n",
    "img_extensions = [\".jpg\", \".jpeg\", \".png\", \".tif\"]\n",
    "all_test_files = [\n",
    "    f for f in os.listdir(test_images_dir)\n",
    "    if os.path.splitext(f)[1].lower() in img_extensions\n",
    "]\n",
    "\n",
    "if not all_test_files:\n",
    "    raise ValueError(\"No valid images found in test_images_dir!\")\n",
    "\n",
    "# Randomly pick one\n",
    "chosen_file = random.choice(all_test_files)\n",
    "test_image_path = os.path.join(test_images_dir, chosen_file)\n",
    "\n",
    "print(\"Randomly chosen test image:\", test_image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inference using the trained model and visualize ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new config for inference\n",
    "inf_cfg = get_cfg()\n",
    "inf_cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# Match the training setup (1 class)\n",
    "inf_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "inf_cfg.MODEL.DEVICE = \"cpu\"  # use \"cuda\" if applicable\n",
    "\n",
    "# Point to the trained weights (model_final.pth should be generated in cfg.OUTPUT_DIR by training)\n",
    "inf_cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "\n",
    "# Set a threshold for predictions (adjust as needed)\n",
    "inf_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "\n",
    "# Create the predictor\n",
    "predictor = DefaultPredictor(inf_cfg)\n",
    "\n",
    "# Read the randomly chosen test image\n",
    "test_image = cv2.imread(test_image_path)\n",
    "if test_image is None:\n",
    "    raise ValueError(\"Failed to read test image: \" + test_image_path)\n",
    "\n",
    "# Run inference\n",
    "outputs = predictor(test_image)\n",
    "\n",
    "# Retrieve metadata for visualization (ensure your dataset registration set thing_classes=[\"roof\"])\n",
    "roof_metadata = MetadataCatalog.get(\"roof_train\")  # or \"roof_val\" if that's how you registered it\n",
    "\n",
    "# Visualize predictions on the test image\n",
    "v = Visualizer(test_image[:, :, ::-1], metadata=roof_metadata, scale=0.8)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(out.get_image()[:, :, ::-1])\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data generators for roof type classification ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "train_dir = 'path/to/roof_type/train'\n",
    "val_dir = 'path/to/roof_type/val'\n",
    "\n",
    "# Image data generators with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the roof type classification model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform obstacle detection using edge detection and color thresholding ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the roof image (segmented roof area)\n",
    "roof_image = cv2.imread('path/to/segmented/roof_image.jpg')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(roof_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(gray, threshold1=50, threshold2=150)\n",
    "\n",
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours on a mask\n",
    "obstacle_mask = np.zeros_like(gray)\n",
    "cv2.drawContours(obstacle_mask, contours, -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "# Optional: Use color thresholding to refine obstacle detection\n",
    "hsv = cv2.cvtColor(roof_image, cv2.COLOR_BGR2HSV)\n",
    "lower_val = np.array([0, 0, 0])\n",
    "upper_val = np.array([180, 255, 30])  # Adjust values based on obstacle colors\n",
    "color_mask = cv2.inRange(hsv, lower_val, upper_val)\n",
    "\n",
    "# Combine edge and color masks\n",
    "combined_mask = cv2.bitwise_or(obstacle_mask, color_mask)\n",
    "\n",
    "# Visualize the obstacle mask\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(combined_mask, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Obstacle Mask')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the effective roof area excluding obstacles ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume roof_mask is a binary mask of the roof area\n",
    "roof_mask = cv2.imread('path/to/roof_mask.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "roof_area_pixels = cv2.countNonZero(roof_mask)\n",
    "\n",
    "# Obstacle area in pixels\n",
    "obstacle_area_pixels = cv2.countNonZero(combined_mask)\n",
    "\n",
    "# Effective area in pixels\n",
    "effective_area_pixels = roof_area_pixels - obstacle_area_pixels\n",
    "\n",
    "# Spatial resolution in meters per pixel (you need to define this based on your data)\n",
    "resolution = 0.1  # Example: each pixel represents 0.1 meters\n",
    "\n",
    "# Convert to square meters\n",
    "effective_area_m2 = effective_area_pixels * (resolution ** 2)\n",
    "\n",
    "print(f\"Effective roof area available for solar panels: {effective_area_m2:.2f} square meters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect roof faces and calculate orientation angles ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the roof image\n",
    "roof_image = cv2.imread('path/to/roof_image.jpg')\n",
    "gray = cv2.cvtColor(roof_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply edge detection\n",
    "edges = cv2.Canny(gray, threshold1=50, threshold2=150)\n",
    "\n",
    "# Use Hough Line Transform to detect lines\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=50, maxLineGap=10)\n",
    "\n",
    "# Create an empty image to draw lines\n",
    "line_image = np.zeros_like(roof_image)\n",
    "\n",
    "# Draw lines on the image\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(line_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Overlay lines on the original image\n",
    "overlay_image = cv2.addWeighted(roof_image, 0.8, line_image, 1, 0)\n",
    "\n",
    "# Display the image with detected lines\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(overlay_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Detected Roof Faces')\n",
    "plt.show()\n",
    "\n",
    "# Placeholder for normal vector calculation\n",
    "# In reality, you would need 3D coordinates of the roof faces\n",
    "# For demonstration, let's assume a normal vector\n",
    "normal_vector = np.array([0.5, 0.5, 0.7071])  # Example normal vector\n",
    "\n",
    "# Function to calculate orientation\n",
    "import math\n",
    "\n",
    "def calculate_orientation(normal_vector):\n",
    "    nx, ny, nz = normal_vector\n",
    "    azimuth = math.degrees(math.atan2(ny, nx)) % 360\n",
    "    tilt = math.degrees(math.acos(nz / np.linalg.norm(normal_vector)))\n",
    "    return azimuth, tilt\n",
    "\n",
    "azimuth_angle, tilt_angle = calculate_orientation(normal_vector)\n",
    "\n",
    "print(f\"Azimuth Angle: {azimuth_angle:.2f} degrees\")\n",
    "print(f\"Tilt Angle: {tilt_angle:.2f} degrees\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine if the roof face is suitable for solar panel installation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 30 <= tilt_angle <= 40:\n",
    "    print(\"The roof face has an ideal tilt angle for solar panels.\")\n",
    "    suitable_area_m2 = effective_area_m2  # Assuming the entire effective area is suitable\n",
    "else:\n",
    "    print(\"The roof face does not have an ideal tilt angle for solar panels.\")\n",
    "    suitable_area_m2 = 0\n",
    "\n",
    "print(f\"Suitable area for solar panels: {suitable_area_m2:.2f} square meters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate potential energy production ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming average solar irradiance and panel efficiency\n",
    "solar_irradiance = 1000  # W/m^2 (average peak sun hours)\n",
    "panel_efficiency = 0.17  # 17% efficiency\n",
    "system_losses = 0.14     # 14% losses\n",
    "\n",
    "# Calculate the estimated energy production\n",
    "daily_energy_kWh = suitable_area_m2 * solar_irradiance * panel_efficiency * (1 - system_losses) * 4 / 1000\n",
    "\n",
    "print(f\"Estimated daily energy production: {daily_energy_kWh:.2f} kWh\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
