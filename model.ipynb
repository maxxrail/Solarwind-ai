{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Necessary Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade pip\n",
    "%pip install --upgrade pip\n",
    "\n",
    "# Install OpenCV for image processing\n",
    "%pip install opencv-python\n",
    "\n",
    "# Install PyTorch and related packages\n",
    "# Adjust the versions according to your CUDA and Python versions\n",
    "\n",
    "# For CUDA 11.7 and Python 3.10:\n",
    "\n",
    "# Install torch==2.0.0, torchvision==0.15.1, torchaudio==2.0.0\n",
    "%pip install torch==2.0.0+cu117 torchvision==0.15.1+cu117 torchaudio==2.0.0+cu117 --index-url https://download.pytorch.org/whl/cu117\n",
    "\n",
    "# Install gitpython if not already installed\n",
    "%pip install gitpython\n",
    "\n",
    "# Install dependencies\n",
    "%pip install cython\n",
    "%pip install git+https://github.com/facebookresearch/fvcore\n",
    "%pip install git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
    "\n",
    "# Clone the Detectron2 repository and install it\n",
    "import os\n",
    "if not os.path.exists('detectron2'):\n",
    "    !git clone https://github.com/facebookresearch/detectron2.git\n",
    "\n",
    "# Install Detectron2\n",
    "%cd detectron2\n",
    "%pip install -e .\n",
    "%cd ..\n",
    "\n",
    "# Install TensorFlow and Keras for deep learning models\n",
    "%pip install tensorflow==2.10.0\n",
    "\n",
    "# Install pickleshare to fix the IPython warning\n",
    "%pip install pickleshare\n",
    "\n",
    "# Install additional required libraries\n",
    "%pip install numpy matplotlib pandas scikit-learn tqdm Pillow\n",
    "\n",
    "# Install geospatial libraries\n",
    "%pip install geopandas rasterio shapely\n",
    "\n",
    "# Install any other utility libraries if needed\n",
    "%pip install jsonschema pyyaml\n",
    "\n",
    "# Install IPython kernel to ensure compatibility\n",
    "%pip install ipykernel\n",
    "\n",
    "# After installations, you may need to restart the kernel\n",
    "print(\"All libraries installed. Please restart the kernel to ensure all packages are loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to load and register the dataset for Detectron2 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roof_dicts(img_dir):\n",
    "    # Placeholder function to load your dataset\n",
    "    # You need to implement this function to return a list of dictionaries\n",
    "    # Each dictionary corresponds to an image and contains:\n",
    "    # - file_name: path to the image file\n",
    "    # - height: image height\n",
    "    # - width: image width\n",
    "    # - annotations: list of annotations, each with:\n",
    "    #   - segmentation: polygon of the object\n",
    "    #   - bbox: bounding box [x, y, width, height]\n",
    "    #   - bbox_mode: BoxMode.XYWH_ABS\n",
    "    #   - category_id: class id (0 for rooftops)\n",
    "\n",
    "    dataset_dicts = []\n",
    "    # Implement data loading here\n",
    "    return dataset_dicts\n",
    "\n",
    "# Register the dataset\n",
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\"roof_\" + d, lambda d=d: get_roof_dicts(\"path/to/your/dataset/\" + d))\n",
    "    MetadataCatalog.get(\"roof_\" + d).set(thing_classes=[\"roof\"])\n",
    "\n",
    "roof_metadata = MetadataCatalog.get(\"roof_train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize sample data to ensure it's loaded correctly ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = get_roof_dicts(\"path/to/your/dataset/train\")\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=roof_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and train the Mask R-CNN model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"roof_train\",)\n",
    "cfg.DATASETS.TEST = (\"roof_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # Learning rate\n",
    "cfg.SOLVER.MAX_ITER = 1000    # Adjust number of iterations as needed\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only rooftops\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inference using the trained model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # Set the testing threshold\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "test_image = cv2.imread(\"path/to/your/test/image.jpg\")\n",
    "outputs = predictor(test_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the inference results ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualizer(test_image[:, :, ::-1], metadata=roof_metadata, scale=0.8)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(out.get_image()[:, :, ::-1])\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data generators for roof type classification ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "train_dir = 'path/to/roof_type/train'\n",
    "val_dir = 'path/to/roof_type/val'\n",
    "\n",
    "# Image data generators with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the roof type classification model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform obstacle detection using edge detection and color thresholding ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the roof image (segmented roof area)\n",
    "roof_image = cv2.imread('path/to/segmented/roof_image.jpg')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(roof_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(gray, threshold1=50, threshold2=150)\n",
    "\n",
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours on a mask\n",
    "obstacle_mask = np.zeros_like(gray)\n",
    "cv2.drawContours(obstacle_mask, contours, -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "# Optional: Use color thresholding to refine obstacle detection\n",
    "hsv = cv2.cvtColor(roof_image, cv2.COLOR_BGR2HSV)\n",
    "lower_val = np.array([0, 0, 0])\n",
    "upper_val = np.array([180, 255, 30])  # Adjust values based on obstacle colors\n",
    "color_mask = cv2.inRange(hsv, lower_val, upper_val)\n",
    "\n",
    "# Combine edge and color masks\n",
    "combined_mask = cv2.bitwise_or(obstacle_mask, color_mask)\n",
    "\n",
    "# Visualize the obstacle mask\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(combined_mask, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Obstacle Mask')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the effective roof area excluding obstacles ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume roof_mask is a binary mask of the roof area\n",
    "roof_mask = cv2.imread('path/to/roof_mask.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "roof_area_pixels = cv2.countNonZero(roof_mask)\n",
    "\n",
    "# Obstacle area in pixels\n",
    "obstacle_area_pixels = cv2.countNonZero(combined_mask)\n",
    "\n",
    "# Effective area in pixels\n",
    "effective_area_pixels = roof_area_pixels - obstacle_area_pixels\n",
    "\n",
    "# Spatial resolution in meters per pixel (you need to define this based on your data)\n",
    "resolution = 0.1  # Example: each pixel represents 0.1 meters\n",
    "\n",
    "# Convert to square meters\n",
    "effective_area_m2 = effective_area_pixels * (resolution ** 2)\n",
    "\n",
    "print(f\"Effective roof area available for solar panels: {effective_area_m2:.2f} square meters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data generators for roof material classification ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "train_dir = 'path/to/roof_material/train'\n",
    "val_dir = 'path/to/roof_material/val'\n",
    "\n",
    "# Image data generators with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "num_material_classes = len(train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the roof material classification model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_material = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "x = base_model_material.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(num_material_classes, activation='softmax')(x)\n",
    "material_model = Model(inputs=base_model_material.input, outputs=predictions)\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model_material.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "material_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "material_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect roof faces and calculate orientation angles ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the roof image\n",
    "roof_image = cv2.imread('path/to/roof_image.jpg')\n",
    "gray = cv2.cvtColor(roof_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply edge detection\n",
    "edges = cv2.Canny(gray, threshold1=50, threshold2=150)\n",
    "\n",
    "# Use Hough Line Transform to detect lines\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=50, maxLineGap=10)\n",
    "\n",
    "# Create an empty image to draw lines\n",
    "line_image = np.zeros_like(roof_image)\n",
    "\n",
    "# Draw lines on the image\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(line_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Overlay lines on the original image\n",
    "overlay_image = cv2.addWeighted(roof_image, 0.8, line_image, 1, 0)\n",
    "\n",
    "# Display the image with detected lines\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(overlay_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Detected Roof Faces')\n",
    "plt.show()\n",
    "\n",
    "# Placeholder for normal vector calculation\n",
    "# In reality, you would need 3D coordinates of the roof faces\n",
    "# For demonstration, let's assume a normal vector\n",
    "normal_vector = np.array([0.5, 0.5, 0.7071])  # Example normal vector\n",
    "\n",
    "# Function to calculate orientation\n",
    "import math\n",
    "\n",
    "def calculate_orientation(normal_vector):\n",
    "    nx, ny, nz = normal_vector\n",
    "    azimuth = math.degrees(math.atan2(ny, nx)) % 360\n",
    "    tilt = math.degrees(math.acos(nz / np.linalg.norm(normal_vector)))\n",
    "    return azimuth, tilt\n",
    "\n",
    "azimuth_angle, tilt_angle = calculate_orientation(normal_vector)\n",
    "\n",
    "print(f\"Azimuth Angle: {azimuth_angle:.2f} degrees\")\n",
    "print(f\"Tilt Angle: {tilt_angle:.2f} degrees\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine if the roof face is suitable for solar panel installation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 30 <= tilt_angle <= 40:\n",
    "    print(\"The roof face has an ideal tilt angle for solar panels.\")\n",
    "    suitable_area_m2 = effective_area_m2  # Assuming the entire effective area is suitable\n",
    "else:\n",
    "    print(\"The roof face does not have an ideal tilt angle for solar panels.\")\n",
    "    suitable_area_m2 = 0\n",
    "\n",
    "print(f\"Suitable area for solar panels: {suitable_area_m2:.2f} square meters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate potential energy production ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming average solar irradiance and panel efficiency\n",
    "solar_irradiance = 1000  # W/m^2 (average peak sun hours)\n",
    "panel_efficiency = 0.17  # 17% efficiency\n",
    "system_losses = 0.14     # 14% losses\n",
    "\n",
    "# Calculate the estimated energy production\n",
    "daily_energy_kWh = suitable_area_m2 * solar_irradiance * panel_efficiency * (1 - system_losses) * 4 / 1000\n",
    "\n",
    "print(f\"Estimated daily energy production: {daily_energy_kWh:.2f} kWh\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
